{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install libraries\n",
    "!pip install geopy\n",
    "!pip install shapely \n",
    "!pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import geopy as gy\n",
    "import shapely as sy\n",
    "import dask.dataframe as dd\n",
    "import pandasql as pq\n",
    "from shapely.geometry import Point, Polygon\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import sagemaker, boto3, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the path for the file containing ther raw data\n",
    "bucket = 'daen-690-pacific-deviations/raw-data' #Bucket name\n",
    "data_key = 'TOMRDate=2021-12-28.csv' #Name of the CSV file \n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "#Import all of the raw data \n",
    "rawData_df = dd.read_csv(data_location, assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to filter out the needed attribues, rename, and change flight level scale\n",
    "def filterAttributes():\n",
    "    #New dataframe with selected attributes from the raw data\n",
    "    airspaceData_df = rawData_df[[\"FRN73TMRPDateTimeOfMessageRec\",\"FRN131HRPWCFloatingPointLat\",\"FRN131HRPWCFloatingPointLong\",\n",
    "                     \"FRN145FLFlightLevel\", \"FRN170TITargetId\",\"RESHSelectedHeading\",\"FRN80TATargetAddress\",\n",
    "                     \"FRN161TNTrackNumber\"]]\n",
    "\n",
    "    #Rename columns to make it easier to read\n",
    "    airspaceData_df = airspaceData_df.rename(columns={'FRN73TMRPDateTimeOfMessageRec': 'DateTime', \n",
    "                                                      'FRN131HRPWCFloatingPointLat': \"Latitude\", \n",
    "                                                      'FRN131HRPWCFloatingPointLong': \"Longitude\", \n",
    "                                                      'FRN145FLFlightLevel': \"FlightLevel\", \n",
    "                                                      'FRN170TITargetId': \"TargetID\", \n",
    "                                                      'RESHSelectedHeading': \"SelectedHeading\", \n",
    "                                                      'FRN80TATargetAddress': \"TargetAddress\",\n",
    "                                                      'FRN161TNTrackNumber': \"TrackNumber\"})\n",
    "    \n",
    "    \n",
    "    #Change flight level scale to feet (FL1 = 100 ft)\n",
    "    airspaceData_df['FlightLevel'] = airspaceData_df['FlightLevel'].apply(lambda x: x * 100, meta=('FlightLevel', 'float64'))\n",
    "    \n",
    "    #Switch from dask dataframe to pandas\n",
    "    airspaceData = airspaceData_df.compute()\n",
    "    \n",
    "    return airspaceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to format date and time  \n",
    "def timeFormatting(allAircraftData):\n",
    "    \n",
    "    #Reformatting string to conver to time stamp\n",
    "    char = ['T','Z']\n",
    "    for x in char:\n",
    "        allAircraftData[\"DateTime\"] = allAircraftData[\"DateTime\"].str.replace( x ,\" \")\n",
    "\n",
    "    # Saving the Formatted Datetime\n",
    "    allAircraftData[\"DateTime\"] = pd.to_datetime(allAircraftData[\"DateTime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Create 4 new columns for Hour, Minute, Second and Microsecond\n",
    "    allAircraftData[\"Hour\"] = allAircraftData[\"DateTime\"].dt.hour\n",
    "    allAircraftData[\"Minute\"] = allAircraftData[\"DateTime\"].dt.minute\n",
    "    allAircraftData[\"Second\"] = allAircraftData[\"DateTime\"].dt.second\n",
    "    allAircraftData[\"Day\"] = allAircraftData[\"DateTime\"].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Reorder columns\n",
    "    allAircraftData = allAircraftData[[\"DateTime\",\"Day\",\"Hour\",\"Minute\",\"Second\",\"Latitude\",\"Longitude\",\"FlightLevel\",\n",
    "                                   \"TargetID\",\"SelectedHeading\",\"TargetAddress\",\n",
    "                                   \"TrackNumber\"]]\n",
    "    return allAircraftData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to filter for only those flights at or above flight level 240\n",
    "def dataFiltering(): \n",
    "    \n",
    "    global airspaceData\n",
    "    global allAircraftData\n",
    "\n",
    "    #Remove anything below FL240\n",
    "    airspaceData = allAircraftData[(allAircraftData['FlightLevel'] >= 24000)]\n",
    "\n",
    "    #Keep only records for the first 5 seconds to speed up processing time \n",
    "    airspaceData = airspaceData[(airspaceData['Second'] < 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d634d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to filter out anything in the Hawaii airspace\n",
    "def removeHISpace():\n",
    "    \n",
    "    global airspaceData\n",
    "    \n",
    "    #Coordinates for Hawaii airspace\n",
    "    v0 = (26.14472222, -158.62194444) \n",
    "    v1 = (26.105, -160.63166667)\n",
    "    v2 = (25.67611111, -161.69111111)\n",
    "    v3 = (25.05666667, -162.64972222)\n",
    "    v4 = (24.16889, -163.26638889)\n",
    "    v5 = (23.25833, -163.855)\n",
    "    v6 = (22.20555556, -163.91444444)\n",
    "    v7 = (21.1511111, -163.9144444)   \n",
    "    v8 = (20.11666667, -163.3)\n",
    "    v9 = (19.65805556,-162.69944444)\n",
    "    v10 = (19.415, -162.38361111)\n",
    "    v11 = (18.40777778, -160.81416667)\n",
    "    v12 = (18.0525, -160.26972222)\n",
    "    v13 = (17.75583333, -159.53888889)\n",
    "    v14 = (17.17055556, -157.75666667) \n",
    "    v15 = (17.805,-156.06805556)\n",
    "    v16 = (18.10888889, -155.71166667)\n",
    "    v17 = (19.14222222, -154.48333333)\n",
    "    v18 = (19.22293333, -151.87963333)\n",
    "    v19 = (20.69694444, -151.01916667) \n",
    "    v20 = (21.54777778, -151.46638889)\n",
    "    v21 = (22.34416667,-151.88527778)\n",
    "    v22 = (23.02416667, -152.57777778)\n",
    "    v23 = (23.78055556, -153.36611111)\n",
    "    v24 = (24.29583333, -154.25)\n",
    "    v25 = (24.72138889, -155.26305556)\n",
    "    v26 = (25.19583333, -156.42111111)\n",
    "\n",
    "    # Polygon\n",
    "    coords = [v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25, v26]\n",
    "    poly = Polygon(coords)\n",
    "    \n",
    "    #Sort flights into what is in the airspace and what is not\n",
    "    hawaiiAir = []\n",
    "\n",
    "    for loc in range(0,len(airspaceData)):\n",
    "        p1 = Point(airspaceData.iloc[loc][5], airspaceData.iloc[loc][6])\n",
    "        hawaiiAir.append(p1.within(poly))\n",
    "\n",
    "    airspaceData['nearHawaii'] = hawaiiAir\n",
    "    \n",
    "    #Filter out only the ones in the airspace\n",
    "    airspaceData = airspaceData[(airspaceData['nearHawaii'] == False)]\n",
    "    airspaceData = airspaceData.drop(columns=['nearHawaii'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove flights that appear in the record only one time\n",
    "def removeSingleoccurrence():\n",
    "    \n",
    "    global airspaceData\n",
    "    \n",
    "    #Find the target IDs that only appear once\n",
    "    removeFlights = airspaceData['TargetID'].value_counts().rename_axis('targetID').reset_index(name='counts')\n",
    "    removeFlights = removeFlights[(removeFlights['counts'] == 1)].reset_index(drop = True)\n",
    "    \n",
    "    #Remove the flights that only appear once\n",
    "    location = 0\n",
    "    for x in removeFlights:\n",
    "        removeID = removeFlights.loc[location][0]\n",
    "        airspaceData = airspaceData[airspaceData.TargetID.str.contains(removeID) == False].reset_index(drop=True)\n",
    "        location = location + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the direction of aircraft\n",
    "def aircraftDirection():\n",
    "    \n",
    "    global airspaceData\n",
    "    \n",
    "    # Replace missing value with -1\n",
    "    airspaceData['SelectedHeading'] = airspaceData['SelectedHeading'].fillna(-1)\n",
    "    \n",
    "    # Assign Direction \"E\" for 0-180 degree, \"W\" for 180-360 degree, \"NA\" is record with null values \n",
    "    conditionlist = [\n",
    "        (airspaceData['SelectedHeading'] < 0) ,\n",
    "        (airspaceData['SelectedHeading'] >= 0) & (airspaceData['SelectedHeading'] <180),\n",
    "        (airspaceData['SelectedHeading'] > 180)]\n",
    "    choicelist = ['NA', 'E', 'W']\n",
    "    airspaceData['Direction'] = np.select(conditionlist, choicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ea7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Hour and Minute from 'airspaceData' table\n",
    "def minuteFilter(HourCounter,MinuteCounter):\n",
    "    \n",
    "    global airspaceData\n",
    "\n",
    "    #create SQL query for flights between the start and end time\n",
    "    sql1 = \"SELECT *, min(Second) FROM airspaceData WHERE Hour = '{0}' and Minute = '{1}' GROUP BY TargetID ORDER BY TargetID, Second\".format(HourCounter, MinuteCounter)\n",
    "\n",
    "    #Run query and store results\n",
    "    recordsInMinute = pq.sqldf(sql1, globals())\n",
    "    del recordsInMinute['min(Second)']\n",
    "\n",
    "    return (recordsInMinute.sort_values('Longitude').reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39743127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for caluculating distance using 'Haversine formula'\n",
    "def distance_d(point0,pointX):\n",
    "    \n",
    "    # The function \"radians\" is found in the math module\n",
    "    LoA = radians(point0[1])  \n",
    "    LoB = radians(pointX[1])\n",
    "    LaA=  radians(point0[0])  \n",
    "    LaB = radians(pointX[0]) \n",
    "    # The \"Haversine formula\" is used.\n",
    "    D_Lo = LoB - LoA \n",
    "    D_La = LaB - LaA \n",
    "    P = sin(D_La / 2)**2 + cos(LaA) * cos(LaB) * sin(D_Lo / 2)**2  \n",
    "    Q = 2 * asin(sqrt(P))   \n",
    "    \n",
    "    # The earth's radius in kilometers.\n",
    "    R_km = 6371  \n",
    " \n",
    "    # Change the kilometer to  nautical miles\n",
    "    R_nm = R_km*0.539956803\n",
    "\n",
    "    # Then we'll compute the outcome.\n",
    "    return(Q * R_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a45ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up boundary at 25 nm by longitude \n",
    "def limit_lon(point0):\n",
    "    \n",
    "    LaA = radians(point0[0])\n",
    "    # calculate distance for one degree of longitude at this latitude(LaA)\n",
    "    onedeg_long = cos(LaA)*(69.172*0.868976242)\n",
    "    add = 25/onedeg_long \n",
    "    pointlimit = (point0[0],point0[1]+add)\n",
    "    \n",
    "    # return Longitude of pointlimit\n",
    "    return pointlimit[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select, merge and add the values from analyzing Longitude and Latitude\n",
    "def newDF(OrderDF,x,y,d):\n",
    "    \"\"\"DF is Long/LatitudeOrderDF\n",
    "       x = long/latpoint_a\n",
    "       y = long/latpoint_b\n",
    "       d = long/latdistance_ab\"\"\"\n",
    "    # select rows that index is in list 'point_a', 'point_b'\n",
    "    A = OrderDF.loc[x,['DateTime','Day','Hour','Minute','Second','Latitude','Longitude','FlightLevel',\n",
    "                             'TargetID', 'SelectedHeading', 'TargetAddress','Direction']]\n",
    "    B = OrderDF.loc[y,['DateTime','Day','Hour','Minute','Second','Latitude','Longitude','FlightLevel',\n",
    "                             'TargetID', 'SelectedHeading', 'TargetAddress','Direction']]\n",
    "    # Join 2 tables by the \"TargetID\" of point a (for the uniquness)\n",
    "    OrderResult = pd.merge(A.reset_index(drop=True),B.reset_index(drop=True),left_index=True, right_index=True)\n",
    "    # add distance column\n",
    "    OrderResult['Distance'] = d\n",
    "    return OrderResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance of the points closest to each other by longitidue and latitude\n",
    "def proximityCalc(LongitudeOrderDF):\n",
    "    \n",
    "    #Store the points of interest\n",
    "    longpoint_a = []\n",
    "    longpoint_b = []\n",
    "    longdistance_ab = []\n",
    "\n",
    "    #loop through the list to find the proximity of aircraft to each other\n",
    "    for a in LongitudeOrderDF.index:\n",
    "        for n in range(1,len(LongitudeOrderDF)):\n",
    "            b = a+n\n",
    "            if b < len(LongitudeOrderDF):\n",
    "                point0 = LongitudeOrderDF.loc[a,'Latitude'], LongitudeOrderDF.loc[a,'Longitude']\n",
    "                pointX = LongitudeOrderDF.loc[b,'Latitude'], LongitudeOrderDF.loc[b,'Longitude']\n",
    "                # Check if longitude of pointX is within the boundary\n",
    "                if pointX[1] <= limit_lon(point0): \n",
    "                    distance = distance_d(point0,pointX)\n",
    "                    # Check distance within 25 nm\n",
    "                    if distance <= 25: \n",
    "                        longpoint_a.append(a)\n",
    "                        longpoint_b.append(b)\n",
    "                        longdistance_ab.append(distance)\n",
    "                    else:\n",
    "                        break\n",
    "        \n",
    "    # Apply function to select and merge data frame\n",
    "    Resultsdf = newDF(LongitudeOrderDF,longpoint_a, longpoint_b,longdistance_ab)\n",
    "\n",
    "    return (Resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38058880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating height differences\n",
    "def distanceCalc(resultsDF):\n",
    "    \n",
    "    #Store results \n",
    "    heightDifference = []\n",
    "    potentialLoss1000 = []\n",
    "    potentialLoss400 = []\n",
    "    \n",
    "    # Loop through every rows of the input dataframe\n",
    "    for counter in range(0,len(resultsDF)):\n",
    "        difference = abs((resultsDF['FlightLevel_x'][counter]) - (resultsDF['FlightLevel_y'][counter]))\n",
    "        heightDifference.append(difference)\n",
    "        # checkif the difference < 1000\n",
    "        if difference < 1000:\n",
    "            potentialLoss1000.append('True')\n",
    "            # check if the difference <= 400\n",
    "            if difference <= 400:\n",
    "                potentialLoss400.append('True')\n",
    "            else:\n",
    "                potentialLoss400.append('False')\n",
    "        else:\n",
    "            potentialLoss1000.append('False')\n",
    "            potentialLoss400.append('False')\n",
    "            \n",
    "    # Add columns showing hightdifference(ft), potentialLoss400 and 1000\n",
    "    resultsDF['HeightDifference_ft'] = heightDifference\n",
    "    resultsDF['potentialLoss400'] = potentialLoss400\n",
    "    resultsDF['potentialLoss1000'] = potentialLoss1000\n",
    "\n",
    "    return (resultsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing duplicate pairs of aircrafts regardless of order\n",
    "def removeProximityDups(proximityReport):\n",
    "    \n",
    "    #Remove any records that do not have a target ID \n",
    "    proximityReport['TargetID_x'].replace('', np.nan, inplace=True)\n",
    "    proximityReport['TargetID_y'].replace('', np.nan, inplace=True)\n",
    "\n",
    "    proximityReport.dropna(subset=['TargetID_x'], inplace=True)\n",
    "    proximityReport.dropna(subset=['TargetID_y'], inplace=True)\n",
    "    \n",
    "    # sorted targetID in new column 'list_target', then delete the duplicate ones\n",
    "    proximityReport['list_target'] = proximityReport.apply(lambda row: tuple(sorted([row['TargetID_x']]+[row['TargetID_y']])), axis = 1)\n",
    "    proximityReport = proximityReport.drop_duplicates(subset = 'list_target',keep = 'first').reset_index(drop = True)\n",
    "    proximityReport.drop('list_target', axis=1, inplace=True)\n",
    "    \n",
    "    proximityReport = proximityReport[proximityReport.TargetID_x.str.contains(' ') == False].reset_index(drop=True)\n",
    "    proximityReport = proximityReport[proximityReport.TargetID_y.str.contains(' ') == False].reset_index(drop=True)\n",
    "\n",
    "    return proximityReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f909cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through every Hour and Minute, and call function to claculate proximity and hight difference\n",
    "def getProximityReport():\n",
    "    proximityReport = pd.DataFrame()\n",
    "\n",
    "    for HourCounter in range(0,24):\n",
    "        #Create table for the minute\n",
    "        for MinuteCounter in range(0,60):\n",
    "            #Create table for the minute\n",
    "            recordsByMinuteDF = minuteFilter(HourCounter,MinuteCounter)\n",
    "\n",
    "            #calculate proximity\n",
    "            resultsDF = proximityCalc(recordsByMinuteDF)\n",
    "\n",
    "            if resultsDF.empty == True:\n",
    "                # if the results dataframe is empty, then break out of for-loop\n",
    "                break\n",
    "            else:\n",
    "                #Calculate distance\n",
    "                resultsDF = distanceCalc(resultsDF)\n",
    "                #Add the results for this minute to the overall results \n",
    "                proximityReport = pd.concat([proximityReport, resultsDF], ignore_index=True)\n",
    "\n",
    "    #Remove any duplicate entries\n",
    "    proximityReport = removeProximityDups(proximityReport)\n",
    "    \n",
    "    return proximityReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get only results where potentialLoss at 400ft is True\n",
    "def get400candidate(proximityReport):\n",
    "    \n",
    "    #Find records from the proximity report that have been marked as potential loss of separation at 400 ft\n",
    "    LossCandidates400 = proximityReport.loc[(proximityReport['potentialLoss400'] == 'True')]\n",
    "    LossCandidates400 = LossCandidates400.reset_index()\n",
    "    LossCandidates400 = LossCandidates400.drop(columns=['index'])\n",
    "    \n",
    "    if len(LossCandidates400) > 0:\n",
    "        #remove duplicate pairs\n",
    "        LossCandidates400['list_target'] = LossCandidates400.apply(lambda row: tuple(sorted([row['TargetID_x']]+[row['TargetID_y']])), axis = 1)\n",
    "        LossCandidates400 = LossCandidates400.drop_duplicates(subset = ['list_target'],keep = 'last').reset_index(drop = True)\n",
    "        LossCandidates400.drop('list_target', axis=1, inplace=True)\n",
    "\n",
    "    return LossCandidates400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12756a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get only results where potentialLoss at 1000ft is True\n",
    "def get1000candidate(proximityReport):\n",
    "    \n",
    "    #Find records from the proximity report that have been marked as potential loss of separation at 1000 ft\n",
    "    LossCandidates1000 = proximityReport.loc[(proximityReport['potentialLoss1000'] == 'True')]\n",
    "    LossCandidates1000 = LossCandidates1000.reset_index()\n",
    "    LossCandidates1000 = LossCandidates1000.drop(columns=['index'])\n",
    "    \n",
    "    if len(LossCandidates1000) > 0:\n",
    "        #remove duplicate pairs\n",
    "        LossCandidates1000['list_target'] = LossCandidates1000.apply(lambda row: tuple(sorted([row['TargetID_x']]+[row['TargetID_y']])), axis = 1)\n",
    "        LossCandidates1000 = LossCandidates1000.drop_duplicates(subset = ['list_target'],keep = 'last').reset_index(drop = True)\n",
    "        LossCandidates1000.drop('list_target', axis=1, inplace=True)\n",
    "\n",
    "    return LossCandidates1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87710052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the data for the flight at +/- 5 minutes from when the loss of separation was flagged\n",
    "def recordsTable(instancesAtLevel, x):\n",
    "    \n",
    "    #Finds the flights of interest\n",
    "    flight_x = instancesAtLevel['TargetID_x'][x]\n",
    "    flight_y = instancesAtLevel['TargetID_y'][x]\n",
    "    \n",
    "    #Minutes before and after\n",
    "    occuranceTime = instancesAtLevel['DateTime_x'][x]\n",
    "    date_format_str = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    occuranceTime = datetime.strptime(occuranceTime, date_format_str)\n",
    "    \n",
    "    n = 5 #Number of minutes - can be increased or decreased as needed\n",
    "    start_time = occuranceTime - timedelta(minutes=n)\n",
    "    end_time = occuranceTime + timedelta(minutes=n)\n",
    "\n",
    "    #Getting the records from the raw data for +/- N minutes from the flagged separation\n",
    "    flightInformation = allAircraftData.loc[((allAircraftData['TargetID'] == flight_x) | (allAircraftData['TargetID'] == flight_y)) & \n",
    "                                          ((allAircraftData['DateTime'] >= start_time) & (allAircraftData['DateTime'] <= (end_time)))]\n",
    "  \n",
    "    #Assigning an ID to the separations for sorting/filtering as needed\n",
    "    flightInformation = flightInformation.assign(SeparationEntry=x)\n",
    "\n",
    "    return flightInformation.sort_values(by=['SeparationEntry','DateTime', 'TargetID'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b586494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill missing second with linear interpolation \n",
    "def fillSecond(data_x,data_y):\n",
    "    '''This function transform data of target y to be \n",
    "      on the same minute and second as target x'''\n",
    "    # filled with NA in data_y if second_x are not in second_y \n",
    "    Y = data_y.groupby('Minute')['Second'].apply(list).reset_index(name='list')\n",
    "    for i in data_x.index:\n",
    "        min_x = data_x.loc[i,'Minute']\n",
    "        sec_x = data_x.loc[i,'Second']\n",
    "        for n in range(0,len(Y)):\n",
    "            min_y = Y.loc[n,'Minute']\n",
    "            if min_x == min_y:\n",
    "                listsec = Y.loc[n,'list']\n",
    "                if (sec_x not in listsec):\n",
    "                    ydict = {'Minute': min_x, 'Second': sec_x, \n",
    "                   'TargetID': data_y.loc[0,'TargetID']}\n",
    "                    data_y = data_y.append(ydict, ignore_index = True)\n",
    "\n",
    "    # fill NA with linear interpolation method\n",
    "    y_interp = data_y.sort_values(by=['Minute','Second']).interpolate(method='linear', limit_direction ='forward')\n",
    "    y_transformed = y_interp.interpolate(method='linear', limit_direction ='backward')\n",
    "    return y_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da847406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to put data_x and data_y on the same time scale\n",
    "def transformTable(flightData):\n",
    "    for i, id in enumerate(flightData['TargetID'].unique()):\n",
    "        if i == 0:\n",
    "            data_x = flightData[(flightData['TargetID']== id)].reset_index(drop = True)\n",
    "        else:\n",
    "            data_y = flightData[(flightData['TargetID']== id)].reset_index(drop = True)\n",
    "\n",
    "    data_x = data_x[['SeparationEntry','DateTime','Day','Hour','Minute','Second','Latitude','Longitude','FlightLevel','TargetID','SelectedHeading']]\n",
    "    data_y = data_y[['Minute','Second','Latitude','Longitude','FlightLevel','TargetID','SelectedHeading']]\n",
    "    \n",
    "    y_transformed = fillSecond(data_x,data_y)\n",
    "    \n",
    "    analyzedTable = pd.merge(data_x,y_transformed,on=['Minute','Second'], how='left')\n",
    "\n",
    "    #Remove records that the interpolation stored an \"NA\" for in the latitude \n",
    "    analyzedTable['Latitude_y'].replace('', np.nan, inplace=True)\n",
    "    analyzedTable['Latitude_y'].replace('', np.nan, inplace=True)\n",
    "\n",
    "    analyzedTable.dropna(subset=['Latitude_y'], inplace=True)\n",
    "    analyzedTable.dropna(subset=['Latitude_y'], inplace=True)\n",
    "    \n",
    "    return analyzedTable.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance using 'Haversine formula'\n",
    "def haversineAnalysis(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "\n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a))  * 0.539956803 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and append 'LateralDistance' column\n",
    "def getLateralDist(analyzedTable):\n",
    "\n",
    "    analyzedTable['LateralDistance'] = \\\n",
    "    haversineAnalysis(analyzedTable.Latitude_x, analyzedTable.Longitude_x,\n",
    "                 analyzedTable.Latitude_y, analyzedTable.Longitude_y)\n",
    "  \n",
    "    return analyzedTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and append the Flight Level differnece column \n",
    "def flightlevelCalc(analyzedTable):\n",
    "\n",
    "    flightlevelDifference = []\n",
    "\n",
    "    #Subtracting the flight levels to get the difference\n",
    "    for counter in range(0,len(analyzedTable)):\n",
    "        Diff = abs((analyzedTable['FlightLevel_x'][counter]) - (analyzedTable['FlightLevel_y'][counter]))\n",
    "        flightlevelDifference.append(Diff)\n",
    "        \n",
    "    analyzedTable['FlightLevelDifference'] = flightlevelDifference\n",
    "\n",
    "    return analyzedTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify direction of aircraft\n",
    "def getDirection(analyzedTable):\n",
    "\n",
    "    # Direction\n",
    "    conditionsX = [(analyzedTable.iloc[-2]['Longitude_x'] - analyzedTable.iloc[0]['Longitude_x'] < 0),(analyzedTable.iloc[-2]['Longitude_x'] - analyzedTable.iloc[0]['Longitude_x'] > 0)]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['W', 'E']\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    analyzedTable['Direction_x'] = np.select(conditionsX, values)\n",
    "\n",
    "    conditionsY = [\n",
    "      (analyzedTable.iloc[-2]['Longitude_y'] - analyzedTable.iloc[0]['Longitude_y'] < 0),\n",
    "      (analyzedTable.iloc[-2]['Longitude_y'] - analyzedTable.iloc[0]['Longitude_y'] > 0)\n",
    "      ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = ['W', 'E']\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    analyzedTable['Direction_y'] = np.select(conditionsY, values)\n",
    "\n",
    "    #Updated sorting for reasier reading\n",
    "    analyzedTable = analyzedTable[analyzedTable.columns[[0,1,2,3,4,5,6,7,8,9,10,18,11,12,13,14,15,19,16,17]]]\n",
    "\n",
    "    return analyzedTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34844c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to get separation report contains information at loss of separation and 5 minutes before and after\n",
    "def getSeparationReports(instancesAtLevel):\n",
    "    \n",
    "    separationReport = pd.DataFrame()\n",
    "\n",
    "    for x in range(0,len(instancesAtLevel.index)):\n",
    "        #Get the data for the flight at +/- 5 minutes \n",
    "        flightData = recordsTable(instancesAtLevel, x)\n",
    "\n",
    "        #Format the table for output\n",
    "        analyzedTable = transformTable(flightData)\n",
    "\n",
    "        #Compute/assign lateral separation, height separation, and direction\n",
    "        analyzedTable = getLateralDist(analyzedTable)\n",
    "        analyzedTable = flightlevelCalc(analyzedTable)\n",
    "        analyzedTable = getDirection(analyzedTable)\n",
    "\n",
    "        #Add table to the results \n",
    "        separationReport = pd.concat([separationReport, analyzedTable], ignore_index=True)\n",
    "\n",
    "    return separationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get information of only TargetID x\n",
    "def flightXInfo(separationData):\n",
    "\n",
    "    flightX = []\n",
    "    \n",
    "    #Getting the information for just the first flight\n",
    "    for x in range(0, len(separationData.index)):\n",
    "        values_x = [separationData['SeparationEntry'].loc[x], \n",
    "                separationData['DateTime'].loc[x], \n",
    "                separationData['FlightLevel_x'].loc[x], \n",
    "                separationData['TargetID_x'].loc[x], \n",
    "                separationData['Direction_x'].loc[x], \n",
    "                separationData['LateralDistance'].loc[x], \n",
    "                separationData['FlightLevelDifference'].loc[x], \n",
    "                separationData['Longitude_x'].loc[x], \n",
    "                separationData['Latitude_x'].loc[x]]\n",
    "        flightX.append(values_x)\n",
    "\n",
    "    return flightX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0edaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get information of only TargetID y\n",
    "def flightYInfo(separationData):\n",
    "\n",
    "    flightY = []\n",
    "\n",
    "    #Getting the information for just the second flight\n",
    "    for x in range(0, len(separationData.index)):\n",
    "        values_y = [separationData['SeparationEntry'].loc[x],\n",
    "                separationData['DateTime'].loc[x],\n",
    "                separationData['FlightLevel_y'].loc[x], \n",
    "                separationData['TargetID_y'].loc[x], \n",
    "                separationData['Direction_y'].loc[x], \n",
    "                separationData['LateralDistance'].loc[x], \n",
    "                separationData['FlightLevelDifference'].loc[x],\n",
    "                separationData['Longitude_y'].loc[x],\n",
    "                separationData['Latitude_y'].loc[x]]\n",
    "        flightY.append(values_y)\n",
    "\n",
    "    return flightY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c78ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create table for visualization\n",
    "def getVisTable(Resulttable):\n",
    "    \n",
    "    xvalues = pd.DataFrame(flightXInfo(Resulttable))\n",
    "    yvalues = pd.DataFrame(flightYInfo(Resulttable))\n",
    "    \n",
    "    # concatenate by index\n",
    "    tableToVisualize = pd.concat([xvalues, yvalues], ignore_index=True)\n",
    "    \n",
    "    #Renaming columns\n",
    "    tableToVisualize = tableToVisualize.rename(columns={0: 'SeparationEntry',\n",
    "                                                      1: 'DateTime', \n",
    "                                                      2: \"FlightLevel\", \n",
    "                                                      3: \"TargetID\", \n",
    "                                                      4: \"Direction\", \n",
    "                                                      5: \"LateralDistance\",\n",
    "                                                      6: \"FLDifference\",\n",
    "                                                      7: \"Longitude\", \n",
    "                                                      8: \"Latitude\"})\n",
    "\n",
    "    return tableToVisualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the report at the 1000 level\n",
    "def getSeparation1000Report(proximityReport):\n",
    "    \n",
    "    #Get the potential separations at 1000\n",
    "    flSeparation1000Report = get1000candidate(proximityReport)    \n",
    "    \n",
    "    #Get the flight details if there were any potentail separations at the 1000 level\n",
    "    if len(flSeparation1000Report) > 0:\n",
    "        flSeparation1000Report = getSeparationReports(flSeparation1000Report)\n",
    "        \n",
    "    #Remove missing data due to there not being recordings for the time frame around the potential separation\n",
    "    flSeparation1000Report['TargetID_x'].replace('', np.nan, inplace=True)\n",
    "    flSeparation1000Report['TargetID_y'].replace('', np.nan, inplace=True)\n",
    "\n",
    "    flSeparation1000Report.dropna(subset=['TargetID_x'], inplace=True)\n",
    "    flSeparation1000Report.dropna(subset=['TargetID_y'], inplace=True)\n",
    "    \n",
    "    return flSeparation1000Report.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the visualization data at the 1000 level\n",
    "def visualization1000(report1000): \n",
    "    \n",
    "    #If there are any potential separations, get the report with one flight per record/row\n",
    "    if len(report1000) > 0:\n",
    "        viz1000Data = getVisTable(report1000)\n",
    "        #Add a flag to where the potential loss of separation to make the visualizations easier to generate in Tableau\n",
    "        conditions = [\n",
    "            (viz1000Data['FLDifference'] < 1000) & (viz1000Data['LateralDistance'] <= 25),\n",
    "            (viz1000Data['FLDifference'] < 1000) & (viz1000Data['LateralDistance'] > 25),\n",
    "            (viz1000Data['FLDifference'] >= 1000) & (viz1000Data['LateralDistance'] <= 25),\n",
    "            (viz1000Data['FLDifference'] >= 1000) & (viz1000Data['LateralDistance'] > 25),\n",
    "        ]\n",
    "        values = ['True','False','False','False']\n",
    "        viz1000Data['potentialLoss'] = np.select(conditions, values)\n",
    "    else:\n",
    "        #Create an empty table if no recrds exist \n",
    "        column_names = ['SeparationEntry', 'DateTime','FlightLevel','TargetID','Direction','LateralDistance',\n",
    "                       'FLDifference', 'Longitude', 'Latitude']\n",
    "        viz1000Data = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    return viz1000Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the report at the 400 level\n",
    "def getSeparation400Report(proximityReport):\n",
    "    \n",
    "    #Get the potential separations at 400\n",
    "    flSeparation400Report = get400candidate(proximityReport)\n",
    "\n",
    "    #Get the flight details if there were any potentail separations at the 400 level\n",
    "    if len(flSeparation400Report) > 0:\n",
    "        flSeparation400Report = getSeparationReports(flSeparation400Report)\n",
    "        \n",
    "        \n",
    "    #Remove missing data due to there not being recordings for the time frame around the potential separation\n",
    "    flSeparation400Report['TargetID_x'].replace('', np.nan, inplace=True)\n",
    "    flSeparation400Report['TargetID_y'].replace('', np.nan, inplace=True)\n",
    "\n",
    "    flSeparation400Report.dropna(subset=['TargetID_x'], inplace=True)\n",
    "    flSeparation400Report.dropna(subset=['TargetID_y'], inplace=True)\n",
    "    \n",
    "    return flSeparation400Report.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c34af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the visualization data at the 400 level\n",
    "def visualization400(report400):\n",
    "    \n",
    "    #If there are any potential separations, get the report with one flight per record/row\n",
    "    if len(report400) > 0:\n",
    "        viz400Data = getVisTable(report400)\n",
    "        #Add a flag to where the potential loss of separation to make the visualizations easier to generate in Tableau\n",
    "        conditions = [\n",
    "            (viz400Data['FLDifference'] < 400) & (viz400Data['LateralDistance'] <= 25),\n",
    "            (viz400Data['FLDifference'] < 400) & (viz400Data['LateralDistance'] > 25),\n",
    "            (viz400Data['FLDifference'] >= 400) & (viz400Data['LateralDistance'] <= 25),\n",
    "            (viz400Data['FLDifference'] >= 400) & (viz400Data['LateralDistance'] > 25),\n",
    "        ]\n",
    "        values = ['True','False', 'False','False']\n",
    "        viz400Data['potentialLoss'] = np.select(conditions, values)\n",
    "    else:\n",
    "        #Create an empty table if no recrds exist\n",
    "        column_names = ['SeparationEntry', 'DateTime','FlightLevel','TargetID','Direction','LateralDistance',\n",
    "                       'FLDifference', 'Longitude', 'Latitude']\n",
    "        viz400Data = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    return viz400Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to export all report files into S3 bucket\n",
    "def exportFiles(proximityReport, separation400Report, visualization400Report, separation1000Report, visualization1000Report):\n",
    "    \n",
    "    #Get the date for labeling\n",
    "    reportDate = proximityReport['Day_x'][0]\n",
    "    \n",
    "    #Create CSV file for each of the reports\n",
    "    proximityReport.to_csv('proximityReport.csv', index=False, header=True)\n",
    "    separation400Report.to_csv('separation400Report.csv', index=False, header=True)\n",
    "    visualization400Report.to_csv('visualization400Report.csv', index=False, header=True)\n",
    "    separation1000Report.to_csv('separation1000Report.csv', index=False, header=True)\n",
    "    visualization1000Report.to_csv('visualization1000Report.csv', index=False, header=True)\n",
    "    \n",
    "    #Create path for where the files should be stored\n",
    "    bucket = sagemaker.Session().default_bucket()\n",
    "    prefix = \"potential-loss-separation-{0}\".format(reportDate) \n",
    "\n",
    "    #Send the CSV files to the S3 bucket in the path provided above\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'data/proximityReport.csv')).upload_file('proximityReport.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'data/separation400Report.csv')).upload_file('separation400Report.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'data/visualization400Report.csv')).upload_file('visualization400Report.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'data/separation1000Report.csv')).upload_file('separation1000Report.csv')\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "        os.path.join(prefix, 'data/visualization1000Report.csv')).upload_file('visualization1000Report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d59865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call data cleaning steps\n",
    "def cleanAllAircraftData():\n",
    "    \n",
    "    global allAircraftData\n",
    "    \n",
    "    allAircraftData = filterAttributes()\n",
    "    allAircraftData = timeFormatting(allAircraftData)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf52e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call data cleaning steps for analysis\n",
    "def cleanAirspaceData():\n",
    "    \n",
    "    airspaceData = dataFiltering()\n",
    "    airspaceData = removeHISpace()\n",
    "    airspaceData = removeSingleoccurrence()\n",
    "    airspaceData = aircraftDirection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34362734",
   "metadata": {},
   "outputs": [],
   "source": [
    "airspaceData = pd.DataFrame() #Store filtered data\n",
    "allAircraftData = pd.DataFrame() #Store raw data with only the attributes of interest for the project\n",
    "\n",
    "def main():\n",
    "    \n",
    "    global allAircraftData\n",
    "    global airspaceData   \n",
    "\n",
    "    #Functions to call for the data cleanup\n",
    "    cleanAllAircraftData()\n",
    "    cleanAirspaceData()\n",
    "\n",
    "    #Functions to call for the reports\n",
    "    proximityReport = getProximityReport()\n",
    "    separation400Report = getSeparation400Report(proximityReport)\n",
    "    separation1000Report = getSeparation1000Report(proximityReport)\n",
    "    visualization400Report = visualization400(separation400Report)\n",
    "    visualization1000Report = visualization1000(separation1000Report)\n",
    "\n",
    "    #Export and Save reports\n",
    "    exportFiles(proximityReport, separation400Report, visualization400Report, separation1000Report, visualization1000Report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
